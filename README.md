# Deep Learning 1 Course Exercises

## Overview
This repository contains my implementation of various deep learning concepts from the TU Berlin Deep Learning 1 course. The exercises cover fundamental topics in neural networks and deep learning using PyTorch.

## Key Topics Implemented

### 1. Neural Network Fundamentals
- Implemented Multi-Layer Perceptrons (MLPs) for MNIST classification
- Explored different network architectures (fixed vs flexible layer dimensions)
- Compared sequential vs modular network implementations

### 2. Training and Optimization
- Implemented training loops with backpropagation
- Worked with different optimizers (SGD, Adam)
- Analyzed loss curves and model convergence
- Evaluated model performance using accuracy metrics

### 3. Regularization Techniques
- Implemented early stopping to prevent overfitting
- Added dropout layers for regularization
- Compared model performance with/without regularization

### 4. Convolutional Neural Networks
- Built CNNs for CIFAR-10 classification
- Compared CNN performance with MLPs
- Visualized feature maps and filters
- Analyzed robustness to image translations

### 5. Autoencoders
- Implemented encoder-decoder architectures
- Applied autoencoders for anomaly detection
- Visualized latent spaces and reconstructions
- Computed anomaly scores for outlier detection

## Technical Skills Gained
- PyTorch framework proficiency
- Data loading and preprocessing pipelines
- Model evaluation and visualization
- Hyperparameter tuning and experimentation

The exercises provided hands-on experience with fundamental deep learning concepts and their practical implementation.
